{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python script for automatic quality-control procedures (CEMADEN data)\n",
    "# Created on Aug.12.2020\n",
    "### By:\n",
    "    Emerson Freitas\n",
    "    Marcela Antunes\n",
    "    Cristiano Almeida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries used in this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import esda\n",
    "import libpysal as lps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning values to main variables and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data storage path \n",
    "path = 'D:/CEMADEN/' \n",
    "\n",
    "years = [2014 , 2015, 2016, 2017, 2018, 2019,2020] #years used in the analysis\n",
    "states = ['PE','PB','RN','BA','SE','PI','CE','MA','AL','AC','AM','RO','RR','AP','TO','PA','MT',\n",
    "          'MS','DF','GO','RS','SC','PR','ES','MG','RJ','SP'] #states used in the analysis \n",
    "\n",
    "#Filters variables\n",
    "threshold_missing_data_days=60 #days in a year without data\n",
    "threshold_days_without_rain=200 #days in a row without rain \n",
    "threshold_constant_days=35 #days in a row with rain = 0,2mm\n",
    "threshold_max_peak=40 #record of xmm in 10min \n",
    " \n",
    "#Moran's I variables \n",
    "properties=['rainfall_events','mean_rainfall_depth','yearly_rainfall'] #properties calculated based on the events durations defined \n",
    "mits_integer = [60, 360,1439] #mit lenghts used\n",
    "n_neighbors = 5\n",
    "p_value = 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function inserts a beginning and ending date for each code, each year (1st january till 31st december) to compute 365 days \n",
    "\n",
    "def insert_begin_end(df, year, code):\n",
    "    datatemp=str(year)+'-01-01 00:00:10' #temporary date - beginning\n",
    "    data_b = {'gauge_code': [code],\n",
    "        'city': ['x'],\n",
    "        'state': ['x'],\n",
    "        'datetime': [datatemp], #assigning beginning date to code\n",
    "        'rain_mm': [-1], \n",
    "        }\n",
    "\n",
    "    datatemp=str(year)+'-12-31 23:59:10' #temporary date - end\n",
    "    data_e = {'gauge_code': [code],\n",
    "        'city': ['x'],\n",
    "        'state': ['x'],\n",
    "        'datetime': [datatemp],\n",
    "        'rain_mm': [0],\n",
    "        }\n",
    "\n",
    "    df_b = pd.DataFrame(data_b)\n",
    "    df_e = pd.DataFrame(data_e)\n",
    "    df_b['datetime']=pd.to_datetime(df_b['datetime'])\n",
    "    df_e['datetime']=pd.to_datetime(df_e['datetime'])\n",
    "    df=pd.concat([df, df_e], ignore_index=True)\n",
    "    df=pd.concat([df_b, df], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function goes through all the CEMADEN files from all states, each year, to assemble a dataframe with their gauge codes\n",
    "def get_df_codes (year, state):\n",
    "    filename = str(state) +'_'+ str(year) + '.h5'\n",
    "    df_cemaden_info = pd.read_hdf(path+'/data/raw data/'+ filename,'table_info') \n",
    "    df_codes = df_cemaden_info['gauge_code']\n",
    "    return df_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function writes the status (HQ or PQ) on each gauge according to it's classification \n",
    "#from the filters and moran\n",
    "\n",
    "def write_status (code, year, state, status,filter_flag, df_filtered_gauges):\n",
    "    df_filtered_gauges.at[(code, year),'state']=state\n",
    "    df_filtered_gauges.at[(code, year),'status']=status\n",
    "    df_filtered_gauges.at[(code, year),'filter']=filter_flag\n",
    "    return df_filtered_gauges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single gauge tests - Filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Filter All: This function go through all filters in a specific order, and writes the gauge's final status of this step\n",
    "# the function raises a \"flag\" if the gauge doesn't fulfill the condition pre stablished, otherwise, it goes through the next filter\n",
    "\n",
    "def all_filters (code,df_cemaden_data,year,state,df_filtered_gauges):\n",
    "    write=True\n",
    "    flag=False\n",
    "    flag = filter_missing_data_days (code,df_cemaden_data,year,flag,state) #Filter 1 - missing days\n",
    "    if not flag:\n",
    "        flag = filter_consecutive_constant_values (code,df_cemaden_data,year,flag,state) #Filter 2 - consecutive 0.2mm rain days\n",
    "    elif flag and write:\n",
    "        status, filter_flag ='POOR QUALITY','missing_data_days'\n",
    "        df_filtered_gauges= write_status (code,year,state,status,filter_flag,df_filtered_gauges)\n",
    "        write=False\n",
    "    if not flag:\n",
    "        flag = filter_max_peak (code,df_cemaden_data,year,flag,state) #Filter 3 - max peak in 10min\n",
    "    elif flag and write:\n",
    "        status, filter_flag ='POOR QUALITY','consecutive_constant_values'\n",
    "        df_filtered_gauges= write_status (code,year,state,status,filter_flag,df_filtered_gauges)\n",
    "        write=False\n",
    "    if not flag:\n",
    "        flag= filter_consecutive_period_without_rain (code,df_cemaden_data,year,flag,state) #Filter 4- consecutive w/o rain days\n",
    "    elif flag and write:\n",
    "        status, filter_flag ='POOR QUALITY','max_peak'\n",
    "        df_filtered_gauges= write_status (code, year,state,status,filter_flag,df_filtered_gauges)\n",
    "        write=False\n",
    "    if not flag:\n",
    "        status, filter_flag ='HIGH QUALITY','unflagged'\n",
    "        df_filtered_gauges= write_status (code, year,state,status,filter_flag,df_filtered_gauges)\n",
    "        write=False\n",
    "    elif flag and write:\n",
    "        status, filter_flag ='POOR QUALITY','consecutive_period_without_rain'\n",
    "        df_filtered_gauges= write_status (code, year,state,status,filter_flag,df_filtered_gauges)\n",
    "        write=False\n",
    "    return df_filtered_gauges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter: Flags all gauges missing xx or more days of data\n",
    "\n",
    "def filter_missing_data_days (code,df_cemaden_data,year,flag,state):\n",
    "    df_gauge=df_cemaden_data[(df_cemaden_data['gauge_code'] == code )]\n",
    "    df_gauge['rain_mm']=-1 #overwriting all rain values since missing values are substituted by \"0\"\n",
    "    df_gauge=df_gauge.set_index('datetime')\n",
    "    df_gauge_resample=df_gauge['rain_mm'].resample('D').sum() #resampling to obtain the information in \"days\"\n",
    "    number_days_year=get_days (year)\n",
    "    days_without_data= number_days_year - df_gauge_resample[(df_gauge_resample <0)].count()\n",
    "    if days_without_data >= threshold_missing_data_days:\n",
    "        flag=True #raising the flag if the gauge has more missing days in the records than the highest threshold defined\n",
    "    return flag\n",
    "\n",
    "#This function is to identify whether the analyzed year is a leap year \n",
    "def get_days (year): \n",
    "    if (year%4==0 and year%100!=0) or (year%400==0):\n",
    "        nday_year=366\n",
    "    else:\n",
    "        nday_year=365\n",
    "    return nday_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Filter: Exclusion of gauges with consecutive constant values (0.2 mm) per some xx days\n",
    "\n",
    "def filter_consecutive_constant_values (code,df_cemaden_data, year,flag, state):\n",
    "    df_gauge=df_cemaden_data[(df_cemaden_data['gauge_code'] == code ) & (df_cemaden_data['rain_mm']>0)]\n",
    "    df_gauge=df_gauge.set_index('datetime')\n",
    "    t=str(threshold_constant_days)+'D'\n",
    "    df_rolling_mean=df_gauge['rain_mm'].rolling(t).mean()\n",
    "    df_rolling_count=df_gauge['rain_mm'].rolling(t).count()\n",
    "    df_rolling_std=df_gauge['rain_mm'].rolling(t).std()\n",
    "    df_rolling_mean=pd.DataFrame(df_rolling_mean)\n",
    "    df_rolling_mean=df_rolling_mean.rename(columns={'rain_mm':'mean'})\n",
    "    df_rolling_std=pd.DataFrame(df_rolling_std)\n",
    "    df_rolling_std=df_rolling_std.rename(columns={'rain_mm':'std'})\n",
    "    df_rolling_count=pd.DataFrame(df_rolling_count)\n",
    "    df_rolling_count=df_rolling_count.rename(columns={'rain_mm':'count'})\n",
    "    df_rolling_all=pd.concat([df_rolling_mean, df_rolling_std], axis=1)\n",
    "    df_rolling_all=pd.concat([df_rolling_all, df_rolling_count], axis=1)\n",
    "    df_temp=df_rolling_all[(df_rolling_all['mean']< 0.201) & (df_rolling_all['mean']> 0.199) & (df_rolling_all['std']< 0.0001) & (df_rolling_all['count']> 50)] #df['count'] conta quantos pulsos de 0,2 há dentro do período de 10 dias\n",
    "    constant_period=df_temp['count'].count()\n",
    "    if constant_period > 0:\n",
    "        flag=True\n",
    "    return flag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Filter: Flags all gauges with maximum peaks of xx mm or more in 10 minutes\n",
    "\n",
    "def filter_max_peak (code,df_cemaden_data,year,flag,state):\n",
    "    df_temp=df_cemaden_data[(df_cemaden_data['gauge_code'] == code ) & (df_cemaden_data['rain_mm'] > threshold_max_peak)]\n",
    "    if df_temp['rain_mm'].count()>0:\n",
    "        flag=True #raising the flag if the gauge has a higher max peak in the records than the highest threshold defined\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Filter: Flags all gauges with more than xxx consecutive days of null rain records \n",
    "\n",
    "def filter_consecutive_period_without_rain (code,df_cemaden_data, year,flag, state):\n",
    "    df_gauge=df_cemaden_data[(df_cemaden_data['gauge_code'] == code ) & (df_cemaden_data['rain_mm']>0)]\n",
    "    df_gauge['rain_mm']=-1 #overwriting all rain values since missing values are substituted by \"0\"\n",
    "    df_gauge=insert_begin_end(df_gauge, year, code)\n",
    "    df_gauge=df_gauge.set_index('datetime')\n",
    "    df_gauge_resample=df_gauge['rain_mm'].resample('10Min').sum()\n",
    "    df_gauge_resample=pd.DataFrame(df_gauge_resample)\n",
    "    t=str(threshold_days_without_rain)+'D'\n",
    "    df_rolling=df_gauge_resample['rain_mm'].rolling(t).sum() #rolling window to count records at the threshold number of days scale\n",
    "    consecutive_period_without_rain= df_rolling[(df_rolling >= 0)].count()\n",
    "    if consecutive_period_without_rain > 0:\n",
    "        flag=True\n",
    "    return flag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial Analysis - Moran Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spots(df_filter_mit, prop, mit, year):\n",
    "    np.random.seed(999)\n",
    "    y=df_filter_mit[prop]\n",
    "    points = np.array(df_filter_mit[['longitute','latitude']])\n",
    "    wq = lps.weights.KNN(points, n_neighbors)\n",
    "    wq.transform = 'r'\n",
    "    lag_y = lps.weights.lag_spatial(wq, df_filter_mit[prop])\n",
    "    li = esda.moran.Moran_Local(y, wq)\n",
    "    sig = 1 * (li.p_sim < p_value)\n",
    "    hotspot = 1 * (sig * li.q==1)\n",
    "    coldspot = 3 * (sig * li.q==3)\n",
    "    doughnut = 2 * (sig * li.q==2)\n",
    "    diamond = 4 * (sig * li.q==4)\n",
    "    spots = hotspot + coldspot + doughnut + diamond\n",
    "    df_spots=pd.DataFrame(spots)\n",
    "    namecol= prop + '_'+ str(year) +'_'+ str(mit)\n",
    "    df_spots=df_spots.rename(columns={0:namecol})\n",
    "    return df_spots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single gauge tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe to be filled with the stations' information and status after single-gauge analysis\n",
    "df_analyzed_gauges = pd.DataFrame(columns=['code','state','year','status','filter'])\n",
    "df_analyzed_gauges=df_analyzed_gauges.set_index(['code','year'])\n",
    "#iterating to analyze all of the years\n",
    "for year in years:\n",
    "    for state in states:\n",
    "        print(state,year)\n",
    "        n_file= str(state) +'_'+ str(year) + '.h5' #name of hdf file to be opened\n",
    "        df_codes=get_df_codes (year, state) #using function to get the codes for given state and year\n",
    "        df_cemaden_data = pd.read_hdf(path+'data/raw data/'+ n_file,'table_data') #opening all hdf files on folder\n",
    "        for code in df_codes: \n",
    "            df_analyzed_gauges = all_filters (code,df_cemaden_data, year, state,df_analyzed_gauges) #applying all filters on the determined order\n",
    "#saving result to folder\n",
    "df_analyzed_gauges.to_csv(path+'results/filtered_gauges_'+str(threshold_missing_data_days)+'days_'+\n",
    "                          str(threshold_constant_days)+'ctedays_'+str(threshold_max_peak)+'mm_'\n",
    "                          +str(threshold_days_without_rain)+'rainlessdays.csv')\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stations with rainfall over \n",
    "df_tabelao= pd.read_csv(path+'data/mit results/Main_results_rainfall_events_2014_2020.csv', sep=',')\n",
    "df_mit=df_tabelao[df_tabelao['yearly_rainfall']>200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moran Index\n",
    "warnings.filterwarnings('ignore')\n",
    "df_analyzed_gauges_moran_results = df_analyzed_gauges.copy()\n",
    "now1 = datetime.now()\n",
    "print(now1)\n",
    "for prop in properties:\n",
    "    for mit in mits_integer:\n",
    "        df_analyzed_gauges_moran = df_analyzed_gauges_moran_results.copy()\n",
    "        df_analyzed_gauges_moran= df_analyzed_gauges_moran[(df_analyzed_gauges_moran['status']=='HIGH QUALITY')]\n",
    "        df_analyzed_gauges_moran=df_analyzed_gauges_moran.reset_index()        \n",
    "        for year in years:\n",
    "            df_high_temp=df_analyzed_gauges_moran[(df_analyzed_gauges_moran['year']==year)]\n",
    "            df_info_gauges_mit = df_mit.loc[df_mit['gauge_code'].isin(df_high_temp['code'])] \n",
    "            df_info_gauges_mit=df_info_gauges_mit[(df_info_gauges_mit['year']==year)]\n",
    "            df_results_moran=df_info_gauges_mit.drop_duplicates(subset=['gauge_code'], keep='first')\n",
    "            df_results_moran=df_results_moran[['gauge_code','state','longitute','latitude']]\n",
    "            df_results_moran=df_results_moran.reset_index()\n",
    "            df_filter_mit=df_info_gauges_mit[(df_info_gauges_mit['mit_minutes']==mit)]\n",
    "            df_spots=get_spots(df_filter_mit, prop, mit, year)\n",
    "            df_results_moran=pd.concat([df_results_moran, df_spots], axis=1)\n",
    "            df_results_moran['code_index']=df_results_moran['gauge_code']\n",
    "            df_results_moran.set_index('code_index',inplace=True)\n",
    "            df_results_moran.dropna(inplace=True)\n",
    "            for code in df_results_moran['gauge_code']:\n",
    "                col = prop+'_'+str(year)+'_'+str(mit)\n",
    "                if (int(df_results_moran.at[code,col]) == 2) or (int(df_results_moran.at[code,col]) == 4):\n",
    "                    status, filter_flag ='POOR QUALITY',(prop+'_'+str(mit))\n",
    "                    df_analyzed_gauges_moran_results = write_status (code, year, state, status,filter_flag, df_analyzed_gauges_moran_results)\n",
    "df_analyzed_gauges_moran_results.to_csv(path+'results/moran_gauges_knn_'+str(n_neighbors)+'_200mm.csv')\n",
    "df_analyzed_gauges=df_analyzed_gauges.reset_index()\n",
    "now3=datetime.now()\n",
    "print ('finished',now3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
